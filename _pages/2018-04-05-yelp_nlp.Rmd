---
title: "Yelp - NLP"
output: github_document
---

In this post I apply some natural language processing (NLP) techniques to a Yelp dataset containing reviews from users. The idea is to work with text format data and extract meaningful information from it.

```{r setup, include=TRUE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(data.table)
library(ggplot2)
library(dplyr)
library(reshape2)
library(ggridges)
library(tm)
library(stopwords)
library(purrr)
library(h2o)

yelp <- fread("/media/ddantas/OS/udemy/PythonDataScience/Python-Data-Science-and-Machine-Learning-Bootcamp/Machine Learning Sections/Natural-Language-Processing/yelp.csv")
```

## Yelp Data Set

This dataset contains reviews information such as the rating, date of review and the text.

```{r}
knitr::kable(
  head(yelp)
)
```

### Rating Distribution

```{r}
yelp%>%
  group_by(stars)%>%
  summarise(total=n())%>%
  ggplot(aes(x=stars,y=total))+
  geom_col(fill="navy")+theme_minimal()+xlab("# Ratings")+ylab("Stars")
```

Most of the reviews were 4 or 5 stars.

### Reviews

Below, 3 examples of reviews.

```{r}
yelp[23:25,text]
```

How long are these reviews?

```{r, message=FALSE}
yelp[,review_len:=nchar(text)]

ggplot(yelp,aes(x=review_len))+
  geom_histogram(fill="navy")+theme_minimal()+xlab("Review Length")
```

Most of them are lower than 1k characters.

### Very Short Reviews

Example of very short reviews.

```{r}
yelp[review_len<15,text]
```

Some of them are very useful though. Sometimes is better to read 'No good' or 'Excellent' than those long texts.

### The Longest Review

In this dataset the longest review have 5,003 characters. Feel free to read :p

```{r}
cat(yelp[review_len==5003,text])
```

### The Length by Rating

```{r, message=FALSE}
yelp%>%
ggplot(aes(x=log(review_len), y=as.factor(stars)))+
  geom_density_ridges(rel_min_height = 0.01,aes(fill=as.factor(stars)))+
  geom_vline(xintercept = 6.25, lty=2, colour="red")+
  theme_minimal()+ylab("Stars")+xlab("log Review Length")+guides(fill=FALSE)

yelp[stars%in%c(1,5)]%>%
ggplot(aes(x=log(review_len), group=as.factor(stars)))+
  geom_density(aes(fill=as.factor(stars)),alpha=0.6)+
  theme_minimal()+guides(fill=guide_legend(title="Stars"))+xlab("log Review Length")
```

It seems that longer text have a slightly tendency to be a 1 star review. Mayb this information could be useful for the classification.

### Text processing

* Convert letters to lowercase. 
* Remove punctuation and *stopwords*.

```{r}
# Remove punctuation
yelp[,text2:=tolower(gsub("[[:punct:]]","",text))]

# Remove stopwords
t<-unlist(
  map(
    as.list(yelp[,text2]),
    ~tm_map(Corpus(VectorSource(.x)),removeWords,stopwords())[[1]]$content
    )
)

yelp[,text2:=t]
```

```{r, echo=FALSE}
yelp[78,text]
yelp[78,text2]
```



### Prepare dataset to predict 1 or 5 stars based on review text

Create dataset with **term frequency-inverse document frequency** (TF-IDF).

```{r, message=FALSE}
# Select only cases with 1 or 5 stars review
df <- yelp[stars%in%c(1,5)]

df_corpus <- Corpus(VectorSource(df$text2))

df_dtm_tfidf<-DocumentTermMatrix(df_corpus, control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))

df_dtm_tfidf = removeSparseTerms(df_dtm_tfidf, 0.99)

inspect(df_dtm_tfidf[15:20, 10:12])
```

Each column represent a word, and row the document. The value zero means the word is not presented on that review. Values greater than zero are the TF-IDF:

$$W_{i,j} = T_{i,j} * log(\frac{N}{df_i})$$

$T_{i,j}$: Number of times the term $i$ is presented in the review $j$.


$N$: Number of reviews.


$df_{i}$: Number of reviews where the term $i$ is presented.

Example:

The term **'wallet'** appears 3 times in the review **101**. There are 10,000 reviews and 100 of them have the word **'wallet'** then:

$$W_{wallet,101}=T_{wallet,101}*log(\frac{N}{df_{wallet}})$$

$$W_{wallet,101}=3*log(\frac{10,000}{100})$$

$$W_{wallet,101}=3*2=6$$


### Distribution of amount terms

```{r}
df_dtm_tf<-removeSparseTerms(DocumentTermMatrix(df_corpus),0.99)
freq<-apply(as.matrix(df_dtm_tf),2,sum)
freq<-data.frame(word=names(freq),count=freq,row.names = NULL)

freq%>%
  ggplot(aes(log(count)))+
  geom_density(fill="navy",alpha=0.6)+
  theme_minimal()
```

### Most used terms

```{r}
knitr::kable(
  freq%>%
    filter(count>=quantile(count,0.99))%>%
    arrange(desc(count))%>%rename(mentions=count)
  )
```

The word '**place**' is the most mentioned word with 2,469 appearances.


### Model - XGBoost using H2O framework
```{r, results="hide", message=FALSE, warning=FALSE}

# Create dataset with tf-idf for each review and the rating stars.
df_words <- data.frame(as.matrix(df_dtm_tfidf),rating_stars=df$stars)

# Initialize H2O cluster
h2o.init()

# 
df_words_h2o <- as.h2o(df_words)
df_words_h2o$rating_stars<-as.factor(df_words_h2o$rating_stars)

# Split into training and test dataset
split<-h2o.splitFrame(data=df_words_h2o, ratios=0.75)

# Define features and target variables.
features<-names(df_words_h2o)[1:(ncol(df_words_h2o)-1)]
target<-names(df_words_h2o)[ncol(df_words_h2o)]

# Modeling
model <- h2o.xgboost(
  x=features,
  y=target,
  training_frame = split[[1]],
  validation_frame = split[[2]],
  distribution = "bernoulli",
  ntrees = 300,
  sample_rate = 0.7,
  col_sample_rate = 0.5,
  max_depth = 5,
  min_rows = 2,
  learn_rate = 0.2,
  nfolds = 5,
  fold_assignment = "Modulo",
  keep_cross_validation_predictions = TRUE,
  score_each_iteration = TRUE,
  seed=1123
)
```


### logloss by number of trees for training and validation dataset

```{r}
h2o.scoreHistory(model)%>%
  filter(number_of_trees>=0)%>%
  ggplot(aes(x=number_of_trees),legend=TRUE)+
  geom_line(aes(y=training_logloss,colour="navy"))+
  geom_line(aes(y=validation_logloss,colour="dark green"))+
  theme_minimal()+xlab("# of trees")+ylab("")+
  scale_colour_manual('',values=c("dark green", "navy"),labels=c("Test","Training"))
```

For the validation dataset the minimum logloss is around 150 trees.

```{r, echo=FALSE, results="hide"}
model <- h2o.xgboost(
  x=features,
  y=target,
  training_frame = split[[1]],
  validation_frame = split[[2]],
  distribution = "bernoulli",
  ntrees = 150,
  sample_rate = 0.7,
  col_sample_rate = 0.5,
  max_depth = 5,
  min_rows = 2,
  learn_rate = 0.2
)
```

Evaluate the model with 150 trees. Confusion matrix:

```{r, message=FALSE, echo=FALSE, results="hide"}
split[[2]]$predicted <- h2o.predict(model,split[[2]])$predict

t <- table(as.data.frame(split[[2]][,c(ncol(split[[2]])-1,ncol(split[[2]]))]))
```

```{r, echo=FALSE}
t
```

Accuracy:
```{r, echo=FALSE}
1-(t[1]+t[4])/sum(t)
```


